{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00ac8ae3-fd30-4a52-872d-df3c018624b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import of libraries\n",
    "import bgcArgoDMQC\n",
    "import datetime\n",
    "import glob\n",
    "import gsw\n",
    "import os\n",
    "import netCDF4 \n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bgcArgoDMQC.io import netcdf as CGnetcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e5de541-f3e1-44f8-a876-277ab6668320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Global variables & settings\n",
    "# library settings\n",
    "np.set_printoptions(threshold=np.inf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8549231-cf23-4555-849e-1761c04fdfd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select institution and float type\n",
    "#inst_float = 'pmel_apex'\n",
    "inst_float = 'aoml_navis'\n",
    "#inst_float = 'aoml_apex'\n",
    "floatid = -999999 # flag\n",
    "# change this if the profile is not \"overall good\":\n",
    "profile_doxy_qc = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "152d7176-3b95-43ec-bfcb-ed69a10d7622",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# institution and float specific settings\n",
    "# PMEL, APEX floats (testing only)\n",
    "if inst_float == 'pmel_apex':\n",
    "    floatid = 5906293\n",
    "    # directory settings\n",
    "    float_dir = f\"/raid/frenzel/DMQC/ARGO_PROCESSING/DATA/ARGO_REPO/{floatid}/QC/\"\n",
    "    #format: PRIMARY | https://orcid.org/0000-0001-5766-1668 | Tanya Maurer, MBARI\n",
    "    comment_dmqc_operator = \"PRIMARY | https://orcid.org/0000-0002-3481-0867 | Hartmut Frenzel, PMEL\" \n",
    "\n",
    "    # must be 256 characters or less:\n",
    "    scientific_calibration_comment = 'Polynomial calibration coefficients were used. G determined by comparison of O2sat surface measurement to WOA18; DOXY_ADJUSTED_ERROR is set to 2 mbar. See Takeshita et al., 2013, doi:10.1002/jgrc.20399'\n",
    "\n",
    "    history_institution = \"PM\"  # PM for PMEL\n",
    "    history_reference = \"WOA18\" # FIXME not really true since they have in-air calibration, but this is for testing only!\n",
    "\n",
    "    doxy_adj_err = 2 # in mbar, for floats with in-air calibration\n",
    "    \n",
    "    # FIXME - is this always true?\n",
    "    iprof = 1 # use the second entry in the N_PROF dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aee02aa-be2b-4990-93b6-d547d4239c35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# institution and float specific settings\n",
    "# PMEL, Navis floats\n",
    "if inst_float == 'pmel_navis':\n",
    "    floatid = 4903499\n",
    "    #floatid = 4903500\n",
    "    float_dir = f\"/raid/frenzel/DMQC/ARGO_PROCESSING/DATA/ARGO_REPO/{floatid}/QC/\"\n",
    "    #format: PRIMARY | https://orcid.org/0000-0001-5766-1668 | Tanya Maurer, MBARI\n",
    "    comment_dmqc_operator = \"PRIMARY | https://orcid.org/0000-0002-3481-0867 | Hartmut Frenzel, PMEL\"\n",
    "    # must be 256 characters or less:\n",
    "    scientific_calibration_comment = 'Polynomial calibration coefficients were used. G determined by comparison of O2sat surface measurement to WOA18; DOXY_ADJUSTED_ERROR is set to 5 mbar. See Takeshita et al., 2013, doi:10.1002/jgrc.20399'\n",
    "\n",
    "    history_institution = \"PM\"  # PM for PMEL\n",
    "    history_reference = \"WOA18\"\n",
    "    \n",
    "    doxy_adj_err = 5 # in mbar, for floats without in-air calibration\n",
    "    \n",
    "    # FIXME - is this always true?\n",
    "    iprof = 0 # use the first entry in the N_PROF dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55524b4b-643c-40a8-9abb-cc120d7fa0da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# institution and float specific settings\n",
    "# AOML, APEX floats\n",
    "if inst_float == 'aoml_apex':\n",
    "    floatid = 4903622\n",
    "    \n",
    "    float_dir = f\"/Users/madison.soden/BGCARGO_work/data/{floatid}/\"\n",
    "    #DnetCDF_path = /Users/madison.soden/BGCARGO_work/data/reference/netcdf/5905988/BD5905988_012.nc\"\n",
    "    #RnetCDF_path1 = \"/Users/madison.soden/BGCARGO_work/data/4903622/BR4903622_001.nc\"\n",
    "    #RnetCDF_path2 = \"/Users/madison.soden/BGCARGO_work/data/4903622/BR4903622_002.nc\"\n",
    "    #format: PRIMARY | https://orcid.org/0000-0001-5766-1668 | Tanya Maurer, MBARI\n",
    "    comment_dmqc_operator = \"PRIMARY | https://orcid.org/0009-0001-9960-129X | Madison Soden, AOML\" \n",
    "    # must be 256 characters or less\n",
    "    scientific_calibration_comment = 'Polynomial calibration coefficients were used. G determined by surface measurement comparison to NCEP'\n",
    "    \n",
    "    history_institution = \"AO\" # AO for AOML\n",
    "    history_reference = \"NCEP\"\n",
    "    \n",
    "    doxy_adj_err = 2 # in mbar, for floats with in-air calibration\n",
    "    \n",
    "    # FIXME - is this always true?\n",
    "    iprof = 1 # use the second entry in the N_PROF dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "328c0e0c-2ad4-43ea-b5ac-804572219480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# institution and float specific settings\n",
    "# AOML, APEX floats\n",
    "if inst_float == 'aoml_navis':\n",
    "    floatid = 7901009\n",
    "    \n",
    "    float_dir = f\"/Users/madison.soden/BGCARGO_work/data/{floatid}/\"\n",
    "    #DnetCDF_path = /Users/madison.soden/BGCARGO_work/data/reference/netcdf/5905988/BD5905988_012.nc\"\n",
    "    #RnetCDF_path1 = \"/Users/madison.soden/BGCARGO_work/data/4903622/BR4903622_001.nc\"\n",
    "    #RnetCDF_path2 = \"/Users/madison.soden/BGCARGO_work/data/4903622/BR4903622_002.nc\"\n",
    "    #format: PRIMARY | https://orcid.org/0000-0001-5766-1668 | Tanya Maurer, MBARI\n",
    "    comment_dmqc_operator = \"PRIMARY | https://orcid.org/0009-0001-9960-129X | Madison Soden, AOML\" \n",
    "    # must be 256 characters or less\n",
    "    scientific_calibration_comment = 'Polynomial calibration coefficients were used. G determined by surface measurement comparison to NCEP'\n",
    "    \n",
    "    history_institution = \"AO\" # AO for AOML\n",
    "    history_reference = \"NCEP\"\n",
    "    \n",
    "    doxy_adj_err = 5 # in mbar, for floats with in-air calibration\n",
    "    \n",
    "    # FIXME - is this always true?\n",
    "    iprof = 0 # use the second entry in the N_PROF dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f1b3088-295a-436a-b486-18f678f8fc29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if floatid < 0:\n",
    "    raise ValueError('You must select one of the pre-defined institution/float cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "013809e3-8343-4bf0-84bd-c59e7780f531",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# other settings that should apply to all institutions and floats\n",
    "odv_filename = float_dir + f\"ODV{floatid}QC.TXT\"\n",
    "\n",
    "data_state_indicator = ['2','C','','']\n",
    "    # (Ref: Argo Users Manual pgs 85-86) Effectively most cases will change this value from 2B -> 2C for Dmode processing\n",
    "\n",
    "parameter_data_mode = \"D\" \n",
    "    # either \"R\" for real time, or \"D\" for delayed mode\n",
    "    \n",
    "scientific_calibration_equation = 'DOXY_ADJUSTED = DOXY*G; G = G_INIT + G_DRIFT*(JULD_PROF - JULD_INIT)/365' # MBARI version place holder\n",
    "    # must be 256 characters or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14e7ca44-99b9-4af4-a1fb-dd1d88bfe991",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_gain_odvqc(filename, variable='DOXY'):\n",
    "    '''This function retrieves the initial gain and drift values\n",
    "    for the specified variable.\n",
    "    Returns gain and drift.'''\n",
    "    # FIXME written and tested only for DOXY for now!\n",
    "    if variable == 'DOXY':\n",
    "        odv_var = 'Oxygen'\n",
    "    else:\n",
    "        raise ValueError(f'not coded for variable {variable}')\n",
    "    with open(filename, 'r') as f_in:\n",
    "        lines = f_in.readlines()\n",
    "    # find the segment with QC correction values\n",
    "    for count, line in enumerate(lines):\n",
    "        if line.startswith('//QUALITY CONTROLLED DATA CORRECTIONS:'):\n",
    "            break\n",
    "    # now find the line(s) for the specified variable\n",
    "    # FIXME currently only written for exactly one line with gain factor\n",
    "    for line in lines[count+2:]:\n",
    "        if line.startswith('//' + odv_var):\n",
    "            values = line.split()\n",
    "            break\n",
    "    if int(values[1]) != 1 or abs(float(values[3])) > 1e-10:\n",
    "        raise ValueError(f'unexpected values: {values}')\n",
    "    return float(values[2]), float(values[4]) # gain, drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c7d73da-5230-4f5e-a081-c0aa6c1c57ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_juld(filename):\n",
    "    '''Retrieve and return the JULD value from the given file.\n",
    "    NOTE: It is always taken from the value with index \"iprof\".'''\n",
    "    b_file = netCDF4.Dataset(filename, 'r')\n",
    "    juld = b_file.variables['JULD'][iprof]\n",
    "    b_file.close()\n",
    "    return juld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee6d97b7-a7fc-4446-aa89-26443fcd2a94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_iprof_phys(pres_raw, pres_bgc):\n",
    "    '''Determine which profile from the physical PRES values matches\n",
    "    those from the bgc file. Returns the (zero-offset) value if found,\n",
    "    throws an IOError if not found.'''\n",
    "    iprof_phys = -1 # \"not found\" flag\n",
    "    for col in range(pres_raw.shape[0]):\n",
    "        # raw PRES values from phys and bgc files should be identical;\n",
    "        # we'll allow some numerical error\n",
    "        if max(abs(pres_raw[col,:] - pres_bgc[iprof,:])) < 0.1:\n",
    "            iprof_phys = col\n",
    "    if iprof_phys < 0:\n",
    "        raise IOError('Matching PRES values not found')\n",
    "    else:\n",
    "        print(f'Using profile {iprof_phys+1} of {phys_filename} to determine density.')\n",
    "        return iprof_phys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bca40b6b-3e5b-4074-820a-6071651104e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_working_bd_file(filename):\n",
    "    '''Create a working copy of the B file with a leading 'w_' in the name.\n",
    "    Note that a possibly existing working copy will be overwritten without\n",
    "    warning.\n",
    "    Return the name (with full path) of the working copy.'''\n",
    "    path, name = os.path.split(filename)\n",
    "    bd_name = name.replace('BR', 'BD') # no effect if file is named BD*nc already\n",
    "    w_filename = f'{path}/w_{bd_name}'\n",
    "    shutil.copyfile(filename, w_filename)\n",
    "    return w_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61ca9a5b-967d-4bb9-a291-3253d4314879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_phys_filename(bgc_filename):\n",
    "    '''Determine the name of the physical profile file that corresponds\n",
    "    to the given bgc profile file and return it.\n",
    "    Throws an IOError if no corresponding file is found.'''\n",
    "    path, name = os.path.split(bgc_filename)\n",
    "    # it doesn't matter here if bgc file is named BR* or BD*\n",
    "    phys_filename = path + '/' + name.replace(name[0:2], 'D') # try D file first\n",
    "    if not os.path.exists(phys_filename):\n",
    "        phys_filename = path + '/' + name.replace(name[0:2], 'R') # try R file if necessary\n",
    "        print(f'Using phys R file:{phys_filename}')\n",
    "        if not os.path.exists(phys_filename):\n",
    "            raise IOError(f'No corresponding phys file found for {bgc_filename}')\n",
    "    return phys_filename        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2f4c641-2b68-4608-a895-cc5dcd9d4915",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_phys_raw_pres(phys_filename):\n",
    "    '''Extract the raw PRES values from the given physical profile. \n",
    "    Return the full array.\n",
    "    Pre: File must exist; no check is performed.'''\n",
    "    phys_file = netCDF4.Dataset(phys_filename, 'r') # read-only access is enough\n",
    "    pres_raw = phys_file.variables[\"PRES\"][:,:] # for comparison with PRES from BD file\n",
    "    phys_file.close()\n",
    "    return pres_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7118764b-767e-4653-8837-19cae89a0a88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dens(phys_filename, verbose=False):\n",
    "    '''Extract pTS (adjusted if available) from the physical profile file\n",
    "    with the given name. Compute and return density. Also return salinity and temperature.\n",
    "    Pre: File must exist; no check is performed.\n",
    "    FIXME: So far, only existence of adjusted pTS is checked, not the validity\n",
    "    of the values. (If at least one of them is all NaNs, computed density\n",
    "    will be all NaNs as well.)'''\n",
    "    phys_file = netCDF4.Dataset(phys_filename, 'r') # read-only access is enough    \n",
    "    num_adj = 0\n",
    "    try:\n",
    "        temp_var = phys_file.variables[\"TEMP_ADJUSTED\"]\n",
    "        num_adj += 1\n",
    "    except KeyError:\n",
    "        print('TEMP_ADJUSTED not found, using TEMP instead to determine density')\n",
    "        temp_var = phys_file.variables[\"TEMP\"]\n",
    "    try:\n",
    "        psal_var = phys_file.variables[\"PSAL_ADJUSTED\"]\n",
    "        num_adj += 1\n",
    "    except KeyError:\n",
    "        print('PSAL_ADJUSTED not found, using PSAL instead to determine density')\n",
    "        psal_var = phys_file.variables[\"PSAL\"]\n",
    "    try:\n",
    "        pres_var = phys_file.variables[\"PRES_ADJUSTED\"]\n",
    "        num_adj += 1\n",
    "    except KeyError:\n",
    "        print('PRES_ADJUSTED not found, using PRES instead to determine density')\n",
    "        temp_var = phys_file.variables[\"PRES\"]\n",
    "    if num_adj == 3:\n",
    "        if verbose:\n",
    "            print('Using ADJUSTED values of p,T,S to determine density')\n",
    "    elif num_adj == 0:\n",
    "        print('Using RAW values of p,T,S to determine density')\n",
    "    else:\n",
    "        print(f'Found {num_adj} variables - case not coded!')\n",
    "        raise IOError('Unexpected file contents')\n",
    "    temp = temp_var[:,:]\n",
    "    psal = psal_var[:,:]\n",
    "    pres = pres_var[:,:]\n",
    "    phys_file.close()\n",
    "    return gsw.rho_t_exact(psal, temp, pres), psal, temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7257a3a-904a-4afc-872b-b5515fb567c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_sci_calib_coefficient(gain, juld, juld_init):\n",
    "    '''Fills the given values into the scientific calibration coefficient,\n",
    "    which must be a string at most 256 characters long.'''\n",
    "    return f'G_INIT = {gain:.4f}; G_DRIFT = {drift:.4f}; JULD_PROF = {juld:.4f}; JULD_INIT = {juld_init:.4f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec6d1ee7-19ed-4b7f-b74a-6a7f7f1e9950",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using code from Christopher Gordon's library,\n",
    "# but with an added third argument iprof:\n",
    "def update_history(nc, dct, iprof):\n",
    "        '''\n",
    "       Update HISTORY_<PARAM> values in an Argo netCDF file for the specified profile\n",
    "        '''\n",
    "\n",
    "        hix = nc.dimensions['N_HISTORY'].size\n",
    "        for name, value in dct.items():\n",
    "            nc[name][hix,iprof,:] = CGnetcdf.string_to_array(value, nc.dimensions[nc[name].dimensions[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d710243-8f7e-4c5c-b39b-f4928088a103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_history(bgc_file):\n",
    "    '''Write global attributes and HISTORY* variables to the BD file with the given handle.\n",
    "    Also writes out DATE_CREATION and DATE_UPDATE variables.'''\n",
    "    # history_institution and history_reference must be set as global variables\n",
    "    \n",
    "    # Setting Global Attributes for BD file \n",
    "    # Argo Users Manual V3.41.1 ยง2.2.1\n",
    "\n",
    "    # format: 'YYYY-MM-DDTHH:MM:SSZ creation' EG: '2023-03-13T19:25:43Z creation'\n",
    "    bgc_file.history = datetime.datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ creation\")\n",
    "    bgc_file.setncattr('comment_dmqc_operator', comment_dmqc_operator)\n",
    "        \n",
    "    history_step = \"ARSQ\" \n",
    "        # specific to Dmode. See ARGO User Manual section 3.12 Reference table 12: history steps codes \n",
    "    history_software= \"SAGE\" \n",
    "        # specific to Dmode. This code is institution dependent.\n",
    "    history_software_release = \"2023\"\n",
    "        # specific to Dmode. This code is institution dependent. \n",
    "        # Probably not even necessary to use for SAGE. I ended up using the year of the most recent update for SAGE.\n",
    "        # SAGE does not appeare to have release numbers, saving update year as HISTORY_SOFTWARE_RELEASE \n",
    "\n",
    "    # Reference data that is being fed into SAGE. This code is institution dependent.\n",
    "    history_action = \"IP\"\n",
    "        # See ARGO User Manual section 3.7 Reference table 7: history action codes \n",
    "    history_parameter = \"DOXY\" # specific to Dmode DOXY\n",
    "\n",
    "    # Setting History Variables  \n",
    "    # Using code from Christopher Gordon's library,\n",
    "    # but with an added third argument iprof:\n",
    "    '''\n",
    "    Ref https://github.com/ArgoCanada/bgcArgoDMQC/blob/main/bgcArgoDMQC/io/netcdf.py\n",
    "    Christopher Gordon\n",
    "    Fisheries and Oceans Canada\n",
    "    chris.gordon@dfo-mpo.gc.ca\n",
    "\n",
    "    def update_history(nc, dct, iprof):\n",
    "        ''\n",
    "       Update HISTORY_<PARAM> values in an Argo netCDF file for the specified profile\n",
    "        ''\n",
    "\n",
    "        hix = nc.dimensions['N_HISTORY'].size\n",
    "        for name, value in dct.items():\n",
    "            nc[name][hix,iprof,:] = string_to_array(value, nc.dimensions[nc[name].dimensions[-1]])\n",
    "    '''\n",
    "\n",
    "    update_history(bgc_file, {\"HISTORY_INSTITUTION\": history_institution, # PM\n",
    "                            \"HISTORY_STEP\": history_step, # specific to Dmode\n",
    "                            \"HISTORY_SOFTWARE\": history_software, # specific to Dmode\n",
    "                            \"HISTORY_SOFTWARE_RELEASE\": history_software_release, # specific to Dmode\n",
    "                            \"HISTORY_REFERENCE\": history_reference, # Reference data that is being fed into SAGE, Institution dependent\n",
    "                            \"HISTORY_DATE\": datetime.datetime.utcnow().strftime(\"%Y%m%d%H%M%S\"),\n",
    "                            \"HISTORY_ACTION\": history_action,\n",
    "                            \"HISTORY_PARAMETER\": history_parameter}, iprof) # specific to Dmode DOXY\n",
    "\n",
    "    # Setting DATE_CREATION and DATE_UPDATE variables; format: YYYYMMDDHHMISS (UTC)\n",
    "    UTCcurrent= datetime.datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    bgc_file.variables[\"DATE_CREATION\"][:] = CGnetcdf.string_to_array(UTCcurrent, bgc_file.dimensions[\"DATE_TIME\"])\n",
    "    bgc_file.variables[\"DATE_UPDATE\"][:] = CGnetcdf.string_to_array(UTCcurrent, bgc_file.dimensions[\"DATE_TIME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ba9b912-7a81-4a4a-be90-9b44a73b99f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_parameter_data_mode(bgc_file):\n",
    "    '''Modify the PARAMETER_DATA_MODE variable in the BD file with the given handle.\n",
    "    Set it to D for DOXY.\n",
    "    Note: Uses iprof (assigned above).'''\n",
    "    ParameterList = bgc_file.variables[\"STATION_PARAMETERS\"][iprof].data.astype(str)\n",
    "    PDMarray = bgc_file.variables[\"PARAMETER_DATA_MODE\"][iprof,:]\n",
    "\n",
    "    for j in range(bgc_file.dimensions[\"N_PARAM\"].size): \n",
    "        PARAMstr = ''.join(ParameterList[j]);\n",
    "        if PARAMstr[:4] == 'DOXY': \n",
    "            PDMarray[j] = parameter_data_mode\n",
    "      \n",
    "    bgc_file.variables[\"PARAMETER_DATA_MODE\"][iprof,:] = PDMarray\n",
    "    # adjust the overall DATA_MODE as well (it may be 'D' already)\n",
    "    bgc_file.variables[\"DATA_MODE\"][iprof] = 'D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7a86838-6f33-4a7b-9f5b-fd0b2c0be2db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_scientific_calib(bgc_file, scientific_calibration_coefficient):\n",
    "    '''Write the SCIENTIFIC_CALIB_* (DATE, COMMENT, EQUATION, and COEFFICIENT)\n",
    "    variables in the BD file with the given handle.\n",
    "    scientific_calibration_comment and scientific_calibration_equation must\n",
    "    be assigned globally.\n",
    "    Note: Uses iprof (assigned globally).'''\n",
    "    # SCIENTIFIC_CALIB_DATE\n",
    "    UTCcurrent = datetime.datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    #MS bgc_file.variables[\"SCIENTIFIC_CALIB_DATE\"][iprof,:] = CGnetcdf.string_to_array(UTCcurrent, bgc_file.dimensions[\"DATE_TIME\"])\n",
    "\n",
    "    # SCIENTIFIC_CALIB_COMMENT\n",
    "    SciCalComArray = np.ma.empty(shape = (bgc_file.dimensions[\"STRING256\"].size), dtype='|S1')\n",
    "    SciCalComArray[:] = ''\n",
    "    SciCalComArray.mask = True\n",
    "    SciCalComArray[:len(scientific_calibration_comment)] = list(scientific_calibration_comment)\n",
    "\n",
    "    # SCIENTIFIC_CALIB_EQUATION\n",
    "    SciCalEquArray =  np.ma.empty(shape = (bgc_file.dimensions[\"STRING256\"].size), dtype='|S1')\n",
    "    SciCalEquArray[:] = ''\n",
    "    SciCalEquArray.mask = True\n",
    "    SciCalEquArray[:len(scientific_calibration_equation)] = list(scientific_calibration_equation)\n",
    "\n",
    "    # SCIENTIFIC_CALIB_COEFFICIENT\n",
    "    SciCalCoeArray = np.ma.empty(shape = (bgc_file.dimensions[\"STRING256\"].size), dtype='|S1')\n",
    "    SciCalCoeArray[:] = ''\n",
    "    SciCalCoeArray.mask = True\n",
    "    SciCalCoeArray[:len(scientific_calibration_coefficient)] = list(scientific_calibration_coefficient)\n",
    "\n",
    "    ParameterList= bgc_file.variables[\"STATION_PARAMETERS\"][iprof].data.astype(str)\n",
    "    for j in range(bgc_file.dimensions[\"N_PARAM\"].size): \n",
    "        PARAMstr= ''.join(ParameterList[j]);\n",
    "        if PARAMstr[:4] == 'DOXY': \n",
    "            bgc_file.variables['SCIENTIFIC_CALIB_COMMENT'][iprof,0,j,] = SciCalComArray\n",
    "            bgc_file.variables['SCIENTIFIC_CALIB_EQUATION'][iprof, 0, j,] = SciCalEquArray\n",
    "            bgc_file.variables['SCIENTIFIC_CALIB_COEFFICIENT'][iprof, 0, j,] = SciCalCoeArray\n",
    "            bgc_file.variables[\"SCIENTIFIC_CALIB_DATE\"][iprof,0,j,:] = \\\n",
    "                CGnetcdf.string_to_array(UTCcurrent, bgc_file.dimensions[\"DATE_TIME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1d5c084-2a73-4903-aaa0-d46cd998b512",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_doxy_adjusted(bgc_file, gain):\n",
    "    '''Read DOXY values, compute DOXY_ADJUSTED = DOXY * gain, \n",
    "    and write them to the BD file with the given file handle. \n",
    "    Also write DOXY_ADJUSTED_QC values.\n",
    "    Return the masked array DOXY_Adjusted_Array.'''    \n",
    "    doxy = bgc_file.variables['DOXY'][iprof,:]\n",
    "    doxy_adjusted = doxy * gain;\n",
    "    doxy_adjusted_qc = np.empty(shape = (bgc_file.dimensions[\"N_LEVELS\"].size), dtype='|S1')\n",
    "    doxy_adjusted_qc[:] = ' ' # missing value\n",
    "    doxy_adjusted_qc[~doxy_adjusted.mask] = '1'\n",
    "    \n",
    "    bgc_file.variables[\"DOXY_ADJUSTED\"][iprof,:] = doxy_adjusted\n",
    "    bgc_file.variables[\"DOXY_ADJUSTED_QC\"][iprof,:] = doxy_adjusted_qc\n",
    "    return doxy_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eeb6df2b-4027-495b-b1f9-47b812fe1948",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_doxy_adjusted_error(bgc_file, doxy_adj_err_mbar, psal, temp, pres, dens, doxy_adj):\n",
    "    '''Given the (scalar) value of doxy_adj_err_mbar (in mbar), compute it for all\n",
    "    depth levels in umol/kg and write it to the given bgc_file.\n",
    "    Return value is in umol/l.'''\n",
    "    idx_good = np.where(~np.ma.getmask(psal) & ~np.ma.getmask(doxy_adj))\n",
    "    # initialize the error with its full size\n",
    "    doxy_adj_error = np.ma.masked_array(psal.shape[0]*[0.0], mask=np.ma.getmask(psal) | np.ma.getmask(doxy_adj), fill_value=99999.0)\n",
    "    error = bgcArgoDMQC.calc_fixed_doxy_adjusted_error(psal[idx_good], temp[idx_good], pres[idx_good], \n",
    "                                                       fix_err=doxy_adj_err_mbar)\n",
    "    doxy_adj_error[idx_good] = error\n",
    "    # convert to umol/kg\n",
    "    doxy_adj_error_umol_kg = doxy_adj_error * 1e3 / dens\n",
    "    bgc_file.variables[\"DOXY_ADJUSTED_ERROR\"][iprof,:] = doxy_adj_error_umol_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edc7e121-7923-4090-a1ab-bdd9b58b00a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_profile(filename):\n",
    "    '''Extract the profile index from filename, return it as an int.'''\n",
    "    profile = filename[-6:-3]\n",
    "    return int(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b61f0128-a4c5-43d4-84e8-6da1e7813105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def organize_b_files(bd_files, br_files):\n",
    "    '''Sort the B*nc files by profile. If both BR and BD files exist for a given profile,\n",
    "    consider only the BD file. Return the sorted list.'''\n",
    "    ptr_bd = 0\n",
    "    ptr_br = 0\n",
    "    max_br = get_profile(br_files[-1])\n",
    "    if not bd_files: \n",
    "        max_prof= max_br\n",
    "    else: \n",
    "        max_bd = get_profile(bd_files[-1])\n",
    "        max_prof = max(max_bd, max_br)\n",
    "    sorted_b_files = []\n",
    "    # 001 is the first actual profile file\n",
    "    for idx in range(1, max_prof+1):\n",
    "        file_found = False\n",
    "        for ptr in range(ptr_bd, len(bd_files)):\n",
    "            if get_profile(bd_files[ptr]) == idx:\n",
    "                sorted_b_files.append(bd_files[ptr])\n",
    "                ptr_bd = ptr+1\n",
    "                file_found = True\n",
    "                break\n",
    "        if not file_found:\n",
    "            for ptr in range(ptr_br, len(br_files)):\n",
    "                if get_profile(br_files[ptr]) == idx:\n",
    "                    sorted_b_files.append(br_files[ptr])\n",
    "                    ptr_br = ptr+1\n",
    "                    break\n",
    "        # it is possible that neither BD nor BR file exist for an index\n",
    "    return sorted_b_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cefa6025-bbdc-44bf-9c5a-a37f8d704c9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gain = 1.0542, drift = 0.0091\n"
     ]
    }
   ],
   "source": [
    "# extract gain and drift values from ODV*QC.TXT file\n",
    "gain, drift = get_gain_odvqc(odv_filename) # same values for all BD output files\n",
    "print(f'Using gain = {gain}, drift = {drift}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d4e383e-fd52-4ac0-96a0-fba5030b4c72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 relevant B files found in /Users/madison.soden/BGCARGO_work/data/7901009/\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_001.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_001.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_001.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_002.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_002.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_002.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_003.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_003.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_003.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_004.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_004.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_004.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_005.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_005.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_005.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_006.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_006.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_006.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_007.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_007.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_007.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_008.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_008.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_008.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_009.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_009.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_009.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_010.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_010.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_010.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_011.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_011.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_011.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_012.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_012.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_012.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_013.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_013.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_013.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_014.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_014.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_014.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_015.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_015.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_015.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_016.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_016.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_016.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_017.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_017.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_017.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_018.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_018.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_018.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_019.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_019.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_019.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_020.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_020.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_020.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_021.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_021.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_021.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_022.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_022.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_022.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_023.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_023.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_023.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_024.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_024.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_024.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_025.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_025.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_025.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_026.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_026.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_026.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_027.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_027.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_027.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_028.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_028.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_028.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_029.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_029.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_029.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_030.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_030.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_030.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_031.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_031.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_031.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_032.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_032.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_032.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_033.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_033.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_033.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_034.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_034.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_034.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_035.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_035.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_035.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_036.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_036.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_036.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_037.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_037.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_037.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_039.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_039.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_039.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_040.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_040.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_040.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_041.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_041.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_041.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_042.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_042.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_042.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_043.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_043.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_043.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_044.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_044.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_044.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_045.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_045.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_045.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_046.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_046.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_046.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_047.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_047.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_047.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_048.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_048.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_048.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_049.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_049.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_049.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_050.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_050.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_050.nc to determine density.\n",
      "Processing /Users/madison.soden/BGCARGO_work/data/7901009/BR7901009_051.nc\n",
      "Using phys R file:/Users/madison.soden/BGCARGO_work/data/7901009/R7901009_051.nc\n",
      "Using profile 1 of /Users/madison.soden/BGCARGO_work/data/7901009/R7901009_051.nc to determine density.\n"
     ]
    }
   ],
   "source": [
    "# loop over all BR files - they must be present in \"float_dir\" already\n",
    "# FIXME: if both BR and BD file exist for the same profile, both\n",
    "# will be processed (only the BD file should be used!)\n",
    "all_bd_files = glob.glob(f'{float_dir}BD*{floatid}_*.nc')\n",
    "all_bd_files.sort()\n",
    "all_br_files = glob.glob(f'{float_dir}BR*{floatid}_*.nc')\n",
    "all_br_files.sort()\n",
    "sorted_b_files = organize_b_files(all_bd_files, all_br_files)\n",
    "\n",
    "print(f'{len(sorted_b_files)} relevant B files found in {float_dir}')\n",
    "\n",
    "juld_init = get_juld(sorted_b_files[0])\n",
    "    \n",
    "new_bd_files = list()                                 \n",
    "\n",
    "for bgc_filename in sorted_b_files:\n",
    "    print(f'Processing {bgc_filename}')\n",
    "    idx_profile = int(bgc_filename[-6:-3])\n",
    "    w_bgc_filename = create_working_bd_file(bgc_filename)    \n",
    "    # 'a' (append) mode automatically reads previous netcdf format\n",
    "    bgc_file = netCDF4.Dataset(w_bgc_filename, 'a')\n",
    "    write_history(bgc_file)\n",
    "    write_parameter_data_mode(bgc_file)\n",
    "    juld = get_juld(bgc_filename)\n",
    "    scientific_calibration_coefficient = set_sci_calib_coefficient(gain, juld, juld_init)\n",
    "    write_scientific_calib(bgc_file, scientific_calibration_coefficient)\n",
    "    \n",
    "    # setting DATA_STATE_INDICATOR variable\n",
    "    for i in range(bgc_file.dimensions[\"N_PROF\"].size):\n",
    "        if i != iprof: # FIXME is this always correct?\n",
    "            continue\n",
    "        bgc_file.variables[\"DATA_STATE_INDICATOR\"][i] = np.ma.array(data_state_indicator, mask=[False, False, True, True], \n",
    "                                                                    dtype='|S1')\n",
    "    \n",
    "    # compute DOXY_ADJUSTED from DOXY and gain value and write it to BD file    \n",
    "    doxy_adjusted = write_doxy_adjusted(bgc_file, gain)\n",
    "    \n",
    "    # extract variables from corresponding physical profile file\n",
    "    phys_filename = get_phys_filename(bgc_filename)\n",
    "    pres_phys_raw = get_phys_raw_pres(phys_filename)\n",
    "    dens_phys, psal, temp = get_dens(phys_filename)\n",
    "\n",
    "    # need to determine which pTS profile index to use\n",
    "    pres_bgc = bgc_file.variables['PRES'][:,:]\n",
    "    iprof_phys = get_iprof_phys(pres_phys_raw, pres_bgc)\n",
    "    \n",
    "    # calculate DOXY_ADJUSTED_ERROR in umol/kg    \n",
    "    write_doxy_adjusted_error(bgc_file, doxy_adj_err, psal[iprof_phys,:], temp[iprof_phys,:], \n",
    "                              pres_bgc[iprof,:], dens_phys[iprof_phys,:], doxy_adjusted)\n",
    "    \n",
    "    # assign a new overall profile QC flag\n",
    "    bgc_file.variables['PROFILE_DOXY_QC'][iprof] = profile_doxy_qc\n",
    "    \n",
    "    bgc_file.close()\n",
    "    new_bd_files.append(w_bgc_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb315f1d-8b4d-4616-8b52-7071565514bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_001.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_001.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_002.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_002.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_003.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_003.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_004.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_004.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_005.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_005.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_006.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_006.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_007.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_007.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_008.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_008.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_009.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_009.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_010.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_010.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_011.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_011.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_012.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_012.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_013.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_013.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_014.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_014.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_015.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_015.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_016.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_016.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_017.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_017.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_018.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_018.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_019.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_019.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_020.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_020.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_021.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_021.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_022.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_022.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_023.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_023.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_024.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_024.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_025.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_025.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_026.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_026.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_027.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_027.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_028.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_028.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_029.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_029.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_030.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_030.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_031.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_031.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_032.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_032.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_033.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_033.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_034.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_034.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_035.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_035.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_036.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_036.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_037.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_037.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_039.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_039.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_040.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_040.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_041.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_041.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_042.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_042.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_043.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_043.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_044.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_044.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_045.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_045.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_046.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_046.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_047.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_047.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_048.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_048.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_049.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_049.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_050.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_050.nc\n",
      "Renaming /Users/madison.soden/BGCARGO_work/data/7901009/w_BD7901009_051.nc to /Users/madison.soden/BGCARGO_work/data/7901009/BD7901009_051.nc\n"
     ]
    }
   ],
   "source": [
    "# change w_BDfileName to BDfileName after everything is done\n",
    "for file in new_bd_files:\n",
    "    path, name = os.path.split(file)\n",
    "    new_name = name.replace('w_BD', 'BD')\n",
    "    new_path = f'{path}/{new_name}'\n",
    "    print(f'Renaming {file} to {new_path}')\n",
    "    os.rename(file, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69b68e5-bb43-4380-9a75-4304167b5b92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Argo_jupyter] *",
   "language": "python",
   "name": "conda-env-Argo_jupyter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
