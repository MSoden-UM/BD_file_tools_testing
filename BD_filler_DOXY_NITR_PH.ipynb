{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00ac8ae3-fd30-4a52-872d-df3c018624b6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import of libraries\n",
    "#import bgcArgoDMQC\n",
    "# NO LONGER USED from bgcArgoDMQC.io import netcdf as CGnetcdf\n",
    "import datetime\n",
    "import glob\n",
    "import gsw\n",
    "import os\n",
    "import netCDF4 \n",
    "import shutil\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "from scipy.interpolate import CubicSpline\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3e5f92-dbc3-41fa-b9ed-ce77909c7385",
   "metadata": {},
   "source": [
    "# what is a BR vs BDfile\n",
    "# file checker link and script? \n",
    "# how to tar and send to AOML DAC \n",
    "Make a copy of the BR files and then have a working version of the BD files, then we go into the working BD files and add new variables where we need them. We don’t risk populating the initial data this way. Add new variables, BGC variables, new data. Updating history, meta data, variables, and actual variables. \n",
    "\n",
    "The BD files are then run through a file checker in Java. Run the Java file checker, required by the GDAC. \n",
    "\n",
    "AOML DAC then sends them to iFEMER (GDAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e5de541-f3e1-44f8-a876-277ab6668320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables & settings\n",
    "# library settings\n",
    "\n",
    "np.set_printoptions(threshold=np.inf);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab95041d-8379-4a47-b89a-45d24f3eae78",
   "metadata": {},
   "source": [
    "#modify these 3\n",
    "inst_float = 'aoml_apex'\n",
    "variables = ['DOXY', 'PH_IN_SITU_TOTAL', 'NITRATE']\n",
    "#double check this \n",
    "profile_var_qc = 'A' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8549231-cf23-4555-849e-1761c04fdfd0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select institution and float type\n",
    "#inst_float = 'pmel_apex' \n",
    "#             'pmel_navis'\n",
    "#             'aoml_apex'\n",
    "#             'aoml_navis'\n",
    "inst_float = 'aoml_apex'\n",
    "\n",
    "floatid = -999999 # flag value, *should* be overwritted by actual WMO ID # later in script \n",
    "\n",
    "# change this if the profile is not \"overall good\":\n",
    "profile_var_qc = 'A' \n",
    "''' ARGO USers manual 3.2.2 Reference table 2a: overall profile quality flag\n",
    "https://vocab.nerc.ac.uk/collection/RP2/current\n",
    "N is defined as the percentage of levels with good data where:\n",
    "● QC flag values of 1, 2, 5, 8 (only used in S-files) are GOOD data\n",
    "● QC flag values of 0 (no QC), 9 (missing) or “ “ (FillValue) are NOT USED in the computation\n",
    "● QC flag values of 3, 4 are BAD data\n",
    "A N = 100%; All profile levels contain good data.\n",
    "B 75% <= N < 100%\n",
    "C 50% <= N < 75%\n",
    "D 25% <= N < 50%\n",
    "E 0% < N < 25%\n",
    "F N = 0%; No profile levels have good data\n",
    "'''\n",
    "\n",
    "#variables = ['DOXY', 'PH_IN_SITU_TOTAL', 'NITRATE']\n",
    "variables = [ 'PH_IN_SITU_TOTAL', 'NITRATE']\n",
    "\n",
    "iprof = {}\n",
    "\n",
    "# each must be 256 characters or less:\n",
    "sci_calib_comment = {}\n",
    "sci_calib_eqn = {}\n",
    "history_reference = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "152d7176-3b95-43ec-bfcb-ed69a10d7622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# institution and float specific settings\n",
    "# PMEL, APEX floats (testing only)\n",
    "if inst_float == 'pmel_apex':\n",
    "    raise ValueError('notebook not adapted for pmel_apex!!')\n",
    "    floatid = 5906293\n",
    "    # directory settings\n",
    "    float_dir = f\"/raid/frenzel/DMQC/ARGO_PROCESSING/DATA/ARGO_REPO/{floatid}/QC/\"\n",
    "    #format: PRIMARY | https://orcid.org/0000-0001-5766-1668 | Tanya Maurer, MBARI\n",
    "    comment_dmqc_operator = \"PRIMARY | https://orcid.org/0000-0002-3481-0867 | Hartmut Frenzel\" \n",
    "\n",
    "    # must be 256 characters or less:\n",
    "    scientific_calibration_comment = 'Polynomial calibration coefficients were used. G determined by comparison of O2sat surface measurement to WOA18; DOXY_ADJUSTED_ERROR is set to 2 mbar. See Takeshita et al., 2013, doi:10.1002/jgrc.20399'\n",
    "\n",
    "    history_institution = \"PM\"  # PM for PMEL\n",
    "    history_reference = \"WOA18\" # FIXME not really true since they have in-air calibration, but this is for testing only!\n",
    "\n",
    "    doxy_adj_err = 2 # in mbar, for floats with in-air calibration\n",
    "    \n",
    "    # FIXME - is this always true?\n",
    "    #NEEDS TO BE CHANGED iprof = 1 # use the second entry in the N_PROF dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aee02aa-be2b-4990-93b6-d547d4239c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# institution and float specific settings\n",
    "# PMEL, Navis floats\n",
    "if inst_float == 'pmel_navis':\n",
    "    #floatid = 4903499\n",
    "    floatid = 4903500\n",
    "    float_dir = f\"/raid/frenzel/DMQC/ARGO_PROCESSING/DATA/ARGO_REPO/{floatid}/QC/\"\n",
    "    #format: PRIMARY | https://orcid.org/0000-0001-5766-1668 | Tanya Maurer, MBARI\n",
    "    comment_dmqc_operator = \"PRIMARY | https://orcid.org/0000-0002-3481-0867 | Hartmut Frenzel, PMEL\"\n",
    "    \n",
    "    for var in ['NITRATE', 'PH_IN_SITU_TOTAL']:\n",
    "        sci_calib_comment[var] = 'DMQC follows Maurer et al., 2021 (https://doi.org/10.3389/fmars.2021.683207)'\n",
    "        history_reference[var] = \"ESPER-MIX\"\n",
    "    for var in ['DOXY']:\n",
    "        history_reference[var] = 'WOA'\n",
    "    \n",
    "    doxy_adj_err_mbar = 5 # in mbar, for floats without in-air calibration\n",
    "\n",
    "    history_institution = \"PM\"  # PM for PMEL\n",
    "             \n",
    "    #iprof_doxy = 0 # needed for computation of adjusted error of nitrate and pH\n",
    "    for var in ['DOXY', 'PH_IN_SITU_TOTAL']:\n",
    "        iprof[var] = 0 # use the first entry in the N_PROF dimension\n",
    "    iprof['NITRATE'] = 1 # use the second entry in the N_PROF dimension "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f0c2dd-8cc3-4bc3-a030-9f59846d50b5",
   "metadata": {},
   "source": [
    "Change float id and comment_dmqc_opperatior and scientific_calibration_comment\n",
    "    if you have to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55524b4b-643c-40a8-9abb-cc120d7fa0da",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# institution and float specific settings\n",
    "# AOML, APEX floats\n",
    "if inst_float == 'aoml_apex':\n",
    "    #raise ValueError('notebook not adapted for aoml_apex!')\n",
    "    floatid = 4903622\n",
    "    \n",
    "    float_dir = f\"/Users/madison.soden/Documents/MATLAB/ARGO_PROCESSING/DATA/ARGO_REPO/{floatid}/QC/\"\n",
    "    # for Binder float_dir = f\"../{floatid}/QC/\" \n",
    "    # BGCARGO_work/data/{floatid}/\"\n",
    "    #DnetCDF_path = /Users/madison.soden/BGCARGO_work/data/reference/netcdf/5905988/BD5905988_012.nc\"\n",
    "    #RnetCDF_path1 = \"/Users/madison.soden/BGCARGO_work/data/4903622/BR4903622_001.nc\"\n",
    "    #RnetCDF_path2 = \"/Users/madison.soden/BGCARGO_work/data/4903622/BR4903622_002.nc\"\n",
    "    #format: PRIMARY | https://orcid.org/0000-0001-5766-1668 | Tanya Maurer, MBARI\n",
    "    comment_dmqc_operator = \"PRIMARY | https://orcid.org/0009-0001-9960-129X | Madison Soden, AOML\" \n",
    "    \n",
    "    for var in ['NITRATE', 'PH_IN_SITU_TOTAL']:\n",
    "        sci_calib_comment[var] = 'DMQC follows Maurer et al., 2021 (https://doi.org/10.3389/fmars.2021.683207)'  # must be 256 characters or less\n",
    "        history_reference[var] = \"ESPER-NN\"\n",
    "    for var in ['DOXY']:\n",
    "        history_reference[var] = 'NCEP' #WOA for no in-air claibration, NCEP for in-air calibration\n",
    "        sci_calib_comment[var] = 'Polynomial calibration coefficients were used. G determined by surface measurement comparison to NCEP'  # must be 256 characters or less\n",
    "\n",
    "    \n",
    "    history_institution = \"AO\" # AO for AOML\n",
    "    \n",
    "    doxy_adj_err_mbar = 2 # in mbar, for floats with in-air calibration\n",
    "    \n",
    "    #iprof_doxy = 0 # needed for computation of adjusted error of nitrate and pH\n",
    "    for var in ['DOXY', 'PH_IN_SITU_TOTAL', 'NITRATE']:\n",
    "        iprof[var] = 1 # use the second entry in the N_PROF dimension\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c4a6395-e0e3-42c6-8272-f566d91dd976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# institution and float specific settings\n",
    "# AOML, APEX floats\n",
    "if inst_float == 'aoml_navis':\n",
    "    floatid = 7901009\n",
    "    \n",
    "    float_dir = f\"/Users/madison.soden/Documents/MATLAB/ARGO_PROCESSING/DATA/ARGO_REPO/{floatid}/QC/\"\n",
    "    #DnetCDF_path = /Users/madison.soden/BGCARGO_work/data/reference/netcdf/5905988/BD5905988_012.nc\"\n",
    "    #RnetCDF_path1 = \"/Users/madison.soden/BGCARGO_work/data/4903622/BR4903622_001.nc\"\n",
    "    #RnetCDF_path2 = \"/Users/madison.soden/BGCARGO_work/data/4903622/BR4903622_002.nc\"\n",
    "    #format: PRIMARY | https://orcid.org/0000-0001-5766-1668 | Tanya Maurer, MBARI\n",
    "    comment_dmqc_operator = \"PRIMARY | https://orcid.org/0009-0001-9960-129X | Madison Soden, AOML\" \n",
    "    \n",
    "    for var in ['NITRATE', 'PH_IN_SITU_TOTAL']:\n",
    "        sci_calib_comment[var] = 'DMQC follows Maurer et al., 2021 (https://doi.org/10.3389/fmars.2021.683207)'  # must be 256 characters or less\n",
    "        history_reference[var] = \"ESPER-NN\"\n",
    "    for var in ['DOXY']:\n",
    "        history_reference[var] = 'WOA' #WOA for no in-air claibration, NCEP for in-air calibration\n",
    "        sci_calib_comment[var] = 'Polynomial calibration coefficients were used. G determined by surface measurement comparison to NCEP'  # must be 256 characters or less\n",
    "\n",
    "        \n",
    "    history_institution = \"AO\" # AO for AOML\n",
    "    \n",
    "    doxy_adj_err = 5 # in mbar, for floats with in-air calibration\n",
    "    \n",
    "    for var in ['DOXY', 'PH_IN_SITU_TOTAL']:\n",
    "        iprof[var] = 0 # use the first entry in the N_PROF dimension\n",
    "    iprof['NITRATE'] = 1 # use the second entry in the N_PROF dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f1b3088-295a-436a-b486-18f678f8fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "if floatid < 0:\n",
    "    raise ValueError('You must select one of the pre-defined institution/float cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "013809e3-8343-4bf0-84bd-c59e7780f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other settings that should apply to all institutions and floats\n",
    "odv_filename = float_dir + f\"ODV{floatid}QC.TXT\"\n",
    "\n",
    "data_state_indicator = ['2','C','','']\n",
    "    # (Ref: Argo Users Manual pgs 85-86) Effectively most cases will change this value from 2B -> 2C for Dmode processing\n",
    "\n",
    "parameter_data_mode = \"D\" \n",
    "    # either \"R\" for real time, or \"D\" for delayed mode\n",
    "\n",
    "reference_depth = 1500\n",
    "\n",
    "idx_prof_failure = 100000 # aka \"never\"\n",
    "\n",
    "# must be 256 characters or less\n",
    "sci_calib_eqn = {}\n",
    "sci_calib_eqn['DOXY'] = 'DOXY_ADJUSTED=DOXY*G;G=G_INIT+G_DRIFT(JULD_PROF-JULD_INIT)/365'\n",
    "\n",
    "sci_calib_eqn['NITRATE'] = 'NITRATE_ADJUSTED=[NITRATE-[OFFSET + DRIFT(JULD-JULD_PIVOT)/365]]/GAIN' # MBARI version\n",
    "\n",
    "sci_calib_eqn['PH_IN_SITU_TOTAL'] = 'PH_IN_SITU_TOTAL_ADJUSTED=[PH_IN_SITU_TOTAL+[PUMP_OFFSET - [OFFSET + DRIFT(JULD-JULD_PIVOT)/365]*TCOR]]/GAIN;TCOR=(TREF+273.15)./(TEMP+273.15);  TREF = TEMP at 1500m'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14e7ca44-99b9-4af4-a1fb-dd1d88bfe991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gain_offset_drift_odvqc(filename, variable):\n",
    "    '''This function retrieves the gain, drift, and offset values\n",
    "    for the specified variable, each beginnning with a specific profile.\n",
    "    Returns a dataframe with cycle(station), gain, offset, and drift values.'''\n",
    "    if variable == 'DOXY':\n",
    "        odv_var = 'Oxygen'\n",
    "    elif variable == 'NITRATE':\n",
    "        odv_var = 'Nitrate'\n",
    "    elif variable == 'PH_IN_SITU_TOTAL':\n",
    "        odv_var = 'pH'\n",
    "    else:\n",
    "        raise ValueError(f'not coded for variable {variable}')\n",
    "    with open(filename, 'r') as f_in:\n",
    "        lines = f_in.readlines()\n",
    "    # find the segment with QC correction values\n",
    "    for count, line in enumerate(lines):\n",
    "        if line.startswith('//QUALITY CONTROLLED DATA CORRECTIONS:'):\n",
    "            break\n",
    "    # now find the line(s) for the specified variable\n",
    "    df = pd.DataFrame(columns = ['Station', 'Gain', 'Offset', 'Drift'])\n",
    "    for line in lines[count+2:]: # header line comes after \"//QUALITY CONTROLLED DATA CORRECTIONS\" line\n",
    "        if line.startswith('//' + odv_var):\n",
    "            values = line.split() # creates a list of strings\n",
    "            # skip the first element, which is \"//<odv_var>\"\n",
    "            num_values = [float(i) for i in values[1:]]\n",
    "            df.loc[len(df.index)] = num_values\n",
    "        elif not line.startswith('//'):\n",
    "            break # end of QC section reached\n",
    "\n",
    "    if df.iloc[-1]['Drift'] != 0.0:\n",
    "        raise ValueError('last drift value should be zero!')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6e43740-8569-42a1-b449-8349ff6bd9b8",
   "metadata": {},
   "source": [
    "# FIXME UNNEEDED\n",
    "def get_iprof_phys(pres_raw, pres_bgc):\n",
    "    '''Determine which profile from the physical PRES values matches\n",
    "    those from the bgc file. Returns the (zero-offset) value if found,\n",
    "    throws an IOError if not found.'''\n",
    "    iprof_phys = -1 # \"not found\" flag\n",
    "    for col in range(pres_raw.shape[0]):\n",
    "        # raw PRES values from phys and bgc files should be identical;\n",
    "        # we'll allow some numerical error\n",
    "        if max(abs(pres_raw[col,:] - pres_bgc[iprof[variable],:])) < 0.1:\n",
    "            iprof_phys = col\n",
    "    if iprof_phys < 0:\n",
    "        raise IOError('Matching PRES values not found')\n",
    "    else:\n",
    "        print(f'Using profile {iprof_phys+1} of {phys_filename} to determine density.')\n",
    "        return iprof_phys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bca40b6b-3e5b-4074-820a-6071651104e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_working_bd_file(filename):\n",
    "    '''Create a working copy of the B file with a leading 'w_' in the name.\n",
    "    Note that a possibly existing working copy will be overwritten without\n",
    "    warning.\n",
    "    Return the name (with full path) of the working copy.'''\n",
    "    path, name = os.path.split(filename)\n",
    "    bd_name = name.replace('BR', 'BD') # no effect if file is named BD*nc already\n",
    "    w_filename = f'{path}/w_{bd_name}'\n",
    "    shutil.copyfile(filename, w_filename)\n",
    "    return w_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61ca9a5b-967d-4bb9-a291-3253d4314879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phys_filename(bgc_filename):\n",
    "    '''Determine the name of the physical profile file that corresponds\n",
    "    to the given bgc profile file and return it.\n",
    "    Throws an IOError if no corresponding file is found.'''\n",
    "    path, name = os.path.split(bgc_filename)\n",
    "    # it doesn't matter here if bgc file is named BR* or BD*\n",
    "    phys_filename = path + '/' + name.replace(name[0:2], 'D') # try D file first\n",
    "    if not os.path.exists(phys_filename):\n",
    "        phys_filename = path + '/' + name.replace(name[0:2], 'R') # try R file if necessary\n",
    "        print(f'Using phys R file:{phys_filename}')\n",
    "        if not os.path.exists(phys_filename):\n",
    "            raise IOError(f'No corresponding phys file found for {bgc_filename}')\n",
    "    return phys_filename        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2f4c641-2b68-4608-a895-cc5dcd9d4915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phys_raw_pres(phys_filename):\n",
    "    '''Extract the raw PRES values from the given physical profile. \n",
    "    Return the full array.\n",
    "    Pre: File must exist; no check is performed.'''\n",
    "    phys_file = netCDF4.Dataset(phys_filename, 'r') # read-only access is enough\n",
    "    pres_raw = phys_file.variables[\"PRES\"][:,:] # for comparison with PRES from BD file\n",
    "    phys_file.close()\n",
    "    return pres_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7118764b-767e-4653-8837-19cae89a0a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dens(phys_filename, verbose=False):\n",
    "    '''Extract pTS (adjusted if available) from the physical profile file\n",
    "    with the given name. Compute and return density. Also return salinity and temperature.\n",
    "    Pre: File must exist; no check is performed.\n",
    "    FIXME: So far, only existence of adjusted pTS is checked, not the validity\n",
    "    of the values. (If at least one of them is all NaNs, computed density\n",
    "    will be all NaNs as well.)'''\n",
    "    phys_file = netCDF4.Dataset(phys_filename, 'r') # read-only access is enough    \n",
    "    num_adj = 0\n",
    "    try:\n",
    "        temp_var = phys_file.variables[\"TEMP_ADJUSTED\"]\n",
    "        num_adj += 1\n",
    "    except KeyError:\n",
    "        print('TEMP_ADJUSTED not found, using TEMP instead to determine density')\n",
    "        temp_var = phys_file.variables[\"TEMP\"]\n",
    "    try:\n",
    "        psal_var = phys_file.variables[\"PSAL_ADJUSTED\"]\n",
    "        num_adj += 1\n",
    "    except KeyError:\n",
    "        print('PSAL_ADJUSTED not found, using PSAL instead to determine density')\n",
    "        psal_var = phys_file.variables[\"PSAL\"]\n",
    "    try:\n",
    "        pres_var = phys_file.variables[\"PRES_ADJUSTED\"]\n",
    "        num_adj += 1\n",
    "    except KeyError:\n",
    "        print('PRES_ADJUSTED not found, using PRES instead to determine density')\n",
    "        temp_var = phys_file.variables[\"PRES\"]\n",
    "    if num_adj == 3:\n",
    "        if verbose:\n",
    "            print('Using ADJUSTED values of p,T,S to determine density')\n",
    "    elif num_adj == 0:\n",
    "        print('Using RAW values of p,T,S to determine density')\n",
    "    else:\n",
    "        print(f'Found {num_adj} variables - case not coded!')\n",
    "        raise IOError('Unexpected file contents')\n",
    "    temp = temp_var[:,:]\n",
    "    psal = psal_var[:,:]\n",
    "    pres = pres_var[:,:]\n",
    "    phys_file.close()\n",
    "    return gsw.rho_t_exact(psal, temp, pres), psal, temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b61f0128-a4c5-43d4-84e8-6da1e7813105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_b_files(bd_files, br_files):\n",
    "    '''Sort the B*nc files by profile. If both BR and BD files exist for a given profile,\n",
    "    consider only the BD file. Return the sorted list.'''\n",
    "    ptr_bd = 0\n",
    "    ptr_br = 0    \n",
    "    \n",
    "    max_bd = get_profile(bd_files[-1]) if bd_files else 0 #max_bd = 0 if bd_files is empty \n",
    "    max_br = get_profile(br_files[-1])\n",
    "    max_prof = max(max_bd, max_br)\n",
    "    sorted_b_files = []\n",
    "    # 001 is the first actual profile file\n",
    "    for idx in range(1, max_prof+1):\n",
    "        file_found = False\n",
    "        for ptr in range(ptr_bd, len(bd_files)):\n",
    "            if get_profile(bd_files[ptr]) == idx:\n",
    "                sorted_b_files.append(bd_files[ptr])\n",
    "                ptr_bd = ptr+1\n",
    "                file_found = True\n",
    "                break\n",
    "        if not file_found:\n",
    "            for ptr in range(ptr_br, len(br_files)):\n",
    "                if get_profile(br_files[ptr]) == idx:\n",
    "                    sorted_b_files.append(br_files[ptr])\n",
    "                    ptr_br = ptr+1\n",
    "                    break\n",
    "        # it is possible that neither BD nor BR file exist for an index\n",
    "    return sorted_b_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77da65cf-d41d-4baa-925d-1644a72df6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function comes from Chris Gordon's bgcArgoDMQC Python package (without changes)\n",
    "def string_to_array(s, dim, encode='utf-8'):\n",
    "    '''\n",
    "    Args:\n",
    "        s: input string or comment\n",
    "        dim: netCDF dimension which the string will be made to fill using trailing whitespace\n",
    "        encode (optional): encoding each character, default utf-8 (def. python netCDF format)\n",
    "\n",
    "    Returns:\n",
    "        numpy.array of single letters\n",
    "\n",
    "    Author:\n",
    "        Christopher Gordon\n",
    "        Fisheries and Oceans Canada\n",
    "        chris.gordon@dfo-mpo.gc.ca\n",
    "\n",
    "    Change log:\n",
    "        - 2021-07-05: initial commit\n",
    "    '''\n",
    "\n",
    "    M = dim.size - len(s)\n",
    "    full_string = s + M*' '\n",
    "    str_array = np.array([f'{c}'.encode(encode) for c in full_string])\n",
    "\n",
    "    return str_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f5b81cf-c833-44fe-aab7-c50fdb0be210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function comes from Chris Gordon's bgcArgoDMQC Python package\n",
    "# changes: added the iprof argument (original version runs a loop over all profiles)\n",
    "#          added the incr_hist_dim argument (original version always increases the N_HISTORY dimension)\n",
    "def update_history(nc, dct, iprof, incr_hist_dim=True):\n",
    "    '''\n",
    "    Update HISTORY_<PARAM> values in an Argo netCDF file\n",
    "    '''\n",
    "    hix = nc.dimensions['N_HISTORY'].size\n",
    "    if not incr_hist_dim:\n",
    "        hix -= 1\n",
    "    for name, value in dct.items():\n",
    "        nc[name][hix,iprof,:] = string_to_array(value, nc.dimensions[nc[name].dimensions[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ba9b912-7a81-4a4a-be90-9b44a73b99f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_parameter_data_mode(bgc_file, this_iprof):\n",
    "    '''Modify the PARAMETER_DATA_MODE variable in the BD file with the given handle.\n",
    "    Set it to D for the current variable.'''\n",
    "    ParameterList = bgc_file.variables[\"STATION_PARAMETERS\"][this_iprof].data.astype(str)\n",
    "    PDMarray = bgc_file.variables[\"PARAMETER_DATA_MODE\"][this_iprof,:]\n",
    "    for j in range(bgc_file.dimensions[\"N_PARAM\"].size): \n",
    "        PARAMstr = ''.join(ParameterList[j]);\n",
    "        if PARAMstr[:len(variable)] == variable: \n",
    "            PDMarray[j] = parameter_data_mode\n",
    "        \n",
    "    bgc_file.variables[\"PARAMETER_DATA_MODE\"][this_iprof,:] = PDMarray\n",
    "    # adjust the overall DATA_MODE as well (it may be 'D' already)\n",
    "    bgc_file.variables[\"DATA_MODE\"][this_iprof] = 'D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d710243-8f7e-4c5c-b39b-f4928088a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_history(bgc_file, this_var, this_iprof, incr_hist_dim=True):\n",
    "    '''Write global attributes and HISTORY* variables to the BD file with the given handle.\n",
    "    Also writes out DATE_CREATION and DATE_UPDATE variables.'''\n",
    "    # history_institution and history_reference must be set as global variables\n",
    "    \n",
    "    # Setting Global Attributes for BD file \n",
    "    # Argo Users Manual V3.41.1 §2.2.1\n",
    "\n",
    "    # format: 'YYYY-MM-DDTHH:MM:SSZ creation' EG: '2023-03-13T19:25:43Z creation'\n",
    "    bgc_file.history = datetime.datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ creation\")\n",
    "    bgc_file.setncattr('comment_dmqc_operator', comment_dmqc_operator) # FIXME replace existing?\n",
    "        \n",
    "    history_step = \"ARSQ\" \n",
    "        # specific to Dmode. See ARGO User Manual section 3.12 Reference table 12: history steps codes \n",
    "    history_software= \"SAGE\" \n",
    "        # specific to Dmode. This code is institution dependent.\n",
    "    history_software_release = \"2023\"\n",
    "        # specific to Dmode. This code is institution dependent. \n",
    "        # Probably not even necessary to use for SAGE. I ended up using the year of the most recent update for SAGE.\n",
    "        # SAGE does not appeare to have release numbers, saving update year as HISTORY_SOFTWARE_RELEASE \n",
    "\n",
    "    # Reference data that is being fed into SAGE. This code is institution dependent\n",
    "    # See ARGO User Manual section 3.7 Reference table 7: history action codes\n",
    "    history_action = \"IP\"\n",
    "            \n",
    "    history_parameter = this_var\n",
    "\n",
    "    # Setting History Variables  \n",
    "    # Using code from Christopher Gordon's library, but with added arguments:\n",
    "    update_history(bgc_file, {\"HISTORY_INSTITUTION\": history_institution, # PM\n",
    "                            \"HISTORY_STEP\": history_step, # specific to Dmode\n",
    "                            \"HISTORY_SOFTWARE\": history_software, # specific to Dmode\n",
    "                            \"HISTORY_SOFTWARE_RELEASE\": history_software_release, # specific to Dmode\n",
    "                            \"HISTORY_REFERENCE\": history_reference[this_var], # Reference data that is being fed into SAGE, Institution dependent\n",
    "                            \"HISTORY_DATE\": datetime.datetime.utcnow().strftime(\"%Y%m%d%H%M%S\"),\n",
    "                            \"HISTORY_ACTION\": history_action,\n",
    "                            \"HISTORY_PARAMETER\": history_parameter}, this_iprof, incr_hist_dim) # specific to Dmode\n",
    "    # Setting DATE_CREATION (if it doesn't exist yet) and DATE_UPDATE variables; format: YYYYMMDDHHMISS (UTC)\n",
    "    UTCcurrent = datetime.datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    if 'DATE_CREATION' in bgc_file.variables:\n",
    "        date_creation = bgc_file.variables[\"DATE_CREATION\"][:].tobytes().decode()\n",
    "        if len(date_creation) != 14:            \n",
    "            print(f'date_creation: {date_creation}')\n",
    "            pdb.set_trace() # FIXME\n",
    "            bgc_file.variables[\"DATE_CREATION\"][:] = string_to_array(UTCcurrent, bgc_file.dimensions[\"DATE_TIME\"])\n",
    "    else:\n",
    "        bgc_file.variables[\"DATE_CREATION\"][:] = string_to_array(UTCcurrent, bgc_file.dimensions[\"DATE_TIME\"])\n",
    "    bgc_file.variables[\"DATE_UPDATE\"][:] = string_to_array(UTCcurrent, bgc_file.dimensions[\"DATE_TIME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c7d73da-5230-4f5e-a081-c0aa6c1c57ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variable(filename, var_name, this_iprof=0):\n",
    "    '''Retrieve and return the JULD value from the given file.\".'''\n",
    "    b_file = netCDF4.Dataset(filename, 'r')\n",
    "    value = b_file.variables[var_name][this_iprof].item()\n",
    "    b_file.close()\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8c3cb20-4857-41b9-b5e4-9f17297cdbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dim_len(filename, dim_name):\n",
    "    '''Determine and return the length of the dimension named \"dim_name\".'''\n",
    "    this_file = netCDF4.Dataset(filename, 'r')\n",
    "    dim_len = len(this_file.dimensions[dim_name])\n",
    "    this_file.close()\n",
    "    return dim_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be87c461-6a17-4434-86a7-72b4af59bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_gain_offset_drift(adjustments, cycle):\n",
    "    '''Find the row in dataframe adjustments with a station value that does \n",
    "    not exceed the given cycle. Return that row of the dataframe.'''\n",
    "    # Filter the adjustments dataframe to find stations not larger than cycle\n",
    "    filtered_adj = adjustments[adjustments['Station'] <= cycle]\n",
    "    # Get the row with the highest number in the filtered dataframe\n",
    "    if not filtered_adj.empty:\n",
    "        # contains columns: Station, Gain, Offset, Drift\n",
    "        return filtered_adj.iloc[-1]\n",
    "    else: # this should never happen\n",
    "        raise ValueError(f'cycle is too low: {cycle}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7257a3a-904a-4afc-872b-b5515fb567c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_sci_calib_coefficients(current_adj, juld, juld_pivot):\n",
    "    '''Fills the given values into the scientific calibration coefficient,\n",
    "    which must be a string at most 256 characters long.'''\n",
    "    # Sample output:\n",
    "    # OFFSET = -2.9708; DRIFT = -0.9826; GAIN = 0.9300; JULD = 27120.3596; JULD_PIVOT = 26493.6594\n",
    "    if current_adj is not None:\n",
    "        if variable == 'PH_IN_SITU_TOTAL':\n",
    "            str = 'PUMP_OFFSET = 0; '\n",
    "        else:\n",
    "            str = ''\n",
    "        str += f'OFFSET = {current_adj[\"Offset\"]:.4f}; DRIFT = {current_adj[\"Drift\"]:.4f}; '\n",
    "        str += f'GAIN = {current_adj[\"Gain\"]:.4f}; JULD = {juld:.4f}; JULD_PIVOT = {juld_pivot:.4f}'\n",
    "    else:\n",
    "        if variable == 'PH_IN_SITU_TOTAL':\n",
    "            str = 'PUMP_OFFSET = NAN; '\n",
    "        else:\n",
    "            str = ''\n",
    "        str += f'OFFSET = NAN; DRIFT = NAN; '\n",
    "        str += f'GAIN = NAN; JULD = NAN; JULD_PIVOT = NAN'\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7a86838-6f33-4a7b-9f5b-fd0b2c0be2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_scientific_calib(bgc_file, scientific_calibration_coefficient, this_sci_calib_eqn, this_iprof):\n",
    "    '''Write the SCIENTIFIC_CALIB_* (DATE, COMMENT, EQUATION, and COEFFICIENT)\n",
    "    variables in the BD file with the given handle.\n",
    "    scientific_calibration_comment and scientific_calibration_equation must\n",
    "    be assigned globally.'''\n",
    "    # SCIENTIFIC_CALIB_DATE\n",
    "    UTCcurrent = datetime.datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    #MS bgc_file.variables[\"SCIENTIFIC_CALIB_DATE\"][iprof,:] = CGnetcdf.string_to_array(UTCcurrent, bgc_file.dimensions[\"DATE_TIME\"])\n",
    "\n",
    "    scientific_calibration_comment = sci_calib_comment[variable]\n",
    "    scientific_calibration_equation = this_sci_calib_eqn\n",
    "\n",
    "    # SCIENTIFIC_CALIB_COMMENT\n",
    "    SciCalComArray = np.ma.empty(shape = (bgc_file.dimensions[\"STRING256\"].size), dtype='|S1')\n",
    "    SciCalComArray[:] = ''\n",
    "    SciCalComArray.mask = True\n",
    "    SciCalComArray[:len(scientific_calibration_comment)] = list(scientific_calibration_comment)\n",
    "\n",
    "    # SCIENTIFIC_CALIB_EQUATION\n",
    "    SciCalEquArray =  np.ma.empty(shape = (bgc_file.dimensions[\"STRING256\"].size), dtype='|S1')\n",
    "    SciCalEquArray[:] = ''\n",
    "    SciCalEquArray.mask = True\n",
    "    SciCalEquArray[:len(scientific_calibration_equation)] = list(scientific_calibration_equation)\n",
    "\n",
    "    # SCIENTIFIC_CALIB_COEFFICIENT\n",
    "    SciCalCoeArray = np.ma.empty(shape = (bgc_file.dimensions[\"STRING256\"].size), dtype='|S1')\n",
    "    SciCalCoeArray[:] = ''\n",
    "    SciCalCoeArray.mask = True\n",
    "    SciCalCoeArray[:len(scientific_calibration_coefficient)] = list(scientific_calibration_coefficient)\n",
    "\n",
    "    ParameterList= bgc_file.variables[\"STATION_PARAMETERS\"][this_iprof].data.astype(str)\n",
    "    for j in range(bgc_file.dimensions[\"N_PARAM\"].size): \n",
    "        PARAMstr= ''.join(ParameterList[j]);\n",
    "        if PARAMstr[:len(variable)] == variable: \n",
    "            bgc_file.variables['SCIENTIFIC_CALIB_COMMENT'][this_iprof,0,j,] = SciCalComArray\n",
    "            bgc_file.variables['SCIENTIFIC_CALIB_EQUATION'][this_iprof, 0, j,] = SciCalEquArray\n",
    "            bgc_file.variables['SCIENTIFIC_CALIB_COEFFICIENT'][this_iprof, 0, j,] = SciCalCoeArray\n",
    "            bgc_file.variables[\"SCIENTIFIC_CALIB_DATE\"][this_iprof,0,j,:] = \\\n",
    "                string_to_array(UTCcurrent, bgc_file.dimensions[\"DATE_TIME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2745ac20-437d-4d49-8c39-7d933d1f9a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_adj_err(adj_err, pres, iprof_src, iprof_dest):\n",
    "    '''Interpolate the adjusted error from one pressure axis\n",
    "    (index: iprof_src) to another (index: iprof_dest).\n",
    "    Return the interpolated adjusted error.'''\n",
    "    # determine finite values\n",
    "    pres_src = pres[iprof_src,:]\n",
    "    adj_err_src = adj_err[iprof_src,:]\n",
    "    pres_good = pres_src[~pres_src.mask & ~adj_err_src.mask]\n",
    "    adj_err_good = adj_err_src[~pres_src.mask & ~adj_err_src.mask]\n",
    "    # https://docs.scipy.org/doc/scipy/tutorial/interpolate/extrapolation_examples.html\n",
    "    natural = CubicSpline(pres_good, adj_err_good, bc_type='natural')\n",
    "    adj_err_intp = natural(pres[iprof_dest,:])\n",
    "    pres_dest = pres[iprof_dest,:]\n",
    "    adj_err[iprof_dest] = np.ma.masked_array(adj_err_intp, mask=pres_dest.mask, fill_value=adj_err.fill_value)\n",
    "    return adj_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "441bfc86-d5cc-4381-a1c6-74749e1dcf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_offset(current_adj, this_juld, juld_pivot):\n",
    "    '''Compute and return the total offset for the given Julian day.'''\n",
    "    # total_offset = OFFSET + DRIFT(JULD-JULD_PIVOT)/365]\n",
    "    if current_adj is not None:\n",
    "        return current_adj['Offset'] + current_adj['Drift'] * (this_juld - juld_pivot) / 365.0;\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4bc22e63-99fe-45ee-8718-f1c25893c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_doxy_adjusted(bgc_file, gain):\n",
    "    '''Read DOXY values, compute DOXY_ADJUSTED = DOXY * gain, \n",
    "    and write them to the BD file with the given file handle. \n",
    "    Also write DOXY_ADJUSTED_QC values.\n",
    "    Return the masked array DOXY_Adjusted_Array.'''    \n",
    "    print(type(this_iprof)) \n",
    "    print(this_iprof)\n",
    "    doxy = bgc_file.variables['DOXY'][this_iprof,:]\n",
    "    doxy_adjusted = doxy * gain;\n",
    "    doxy_adjusted_qc = np.empty(shape = (bgc_file.dimensions[\"N_LEVELS\"].size), dtype='|S1')\n",
    "    doxy_adjusted_qc[:] = ' ' # missing value\n",
    "    doxy_adjusted_qc[~doxy_adjusted.mask] = '1'\n",
    "    \n",
    "    bgc_file.variables[\"DOXY_ADJUSTED\"][this_iprof,:] = doxy_adjusted\n",
    "    bgc_file.variables[\"DOXY_ADJUSTED_QC\"][this_iprof,:] = doxy_adjusted_qc\n",
    "    return doxy_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c3659b2-5b87-4218-a4f0-53218d4a167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_doxy_adjusted_error(bgc_file, doxy_adj_err_mbar, psal, temp, pres, dens, doxy_adj):\n",
    "    '''Given the (scalar) value of doxy_adj_err_mbar (in mbar), compute it for all\n",
    "    depth levels in umol/kg and write it to the given bgc_file.\n",
    "    Return value is in umol/l.'''\n",
    "    idx_good = np.where(~np.ma.getmask(psal) & ~np.ma.getmask(doxy_adj))\n",
    "    # initialize the error with its full size\n",
    "    doxy_adj_error = np.ma.masked_array(psal.shape[0]*[0.0], mask=np.ma.getmask(psal) | np.ma.getmask(doxy_adj), fill_value=99999.0)\n",
    "    error = bgcArgoDMQC.calc_fixed_doxy_adjusted_error(psal[idx_good], temp[idx_good], pres[idx_good], \n",
    "                                                       fix_err=doxy_adj_err_mbar)\n",
    "    doxy_adj_error[idx_good] = error\n",
    "    # convert to umol/kg\n",
    "    doxy_adj_error_umol_kg = doxy_adj_error * 1e3 / dens\n",
    "    bgc_file.variables[\"DOXY_ADJUSTED_ERROR\"][this_iprof,:] = doxy_adj_error_umol_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1d5c084-2a73-4903-aaa0-d46cd998b512",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_nitrate_adjusted(bgc_file, offset, gain, this_iprof):\n",
    "    '''Read NITRATE values, compute \n",
    "    NITRATE_ADJUSTED = [NITRATE - offset] / gain, \n",
    "    and write them to the BD file with the given file handle.\n",
    "    Full equation:\n",
    "    NITRATE_ADJUSTED=[NITRATE-[OFFSET + DRIFT(JULD-JULD_PIVOT)/365]]/GAIN\n",
    "    offset = OFFSET + DRIFT(JULD-JULD_PIVOT)/365\n",
    "    Also write NITRATE_ADJUSTED_QC values.\n",
    "    Return the masked array NITRATE_Adjusted_Array.'''\n",
    "    nitrate = bgc_file.variables['NITRATE'][this_iprof,:]\n",
    "    nitrate_qc = bgc_file.variables['NITRATE_QC'][this_iprof,:]\n",
    "    nitrate_adjusted = (nitrate - offset) / gain\n",
    "    nitrate_adjusted_qc = np.empty(shape = (bgc_file.dimensions[\"N_LEVELS\"].size), dtype='|S1')\n",
    "    nitrate_adjusted_qc[:] = ' ' # use missing value as default\n",
    "    nitrate_adjusted_qc[~nitrate_adjusted.mask] = '1'\n",
    "    nitrate_adjusted_qc[~nitrate_qc.mask & nitrate_adjusted.mask] = '9'\n",
    "    # output to netcdf file\n",
    "    bgc_file.variables[\"NITRATE_ADJUSTED\"][this_iprof,:] = nitrate_adjusted\n",
    "    bgc_file.variables[\"NITRATE_ADJUSTED_QC\"][this_iprof,:] = nitrate_adjusted_qc\n",
    "    return nitrate_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eeb6df2b-4027-495b-b1f9-47b812fe1948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_nitrate_adjusted_error(bgc_file, nitr_adj, pres, doxy_adj_err, this_iprof):\n",
    "    '''Given the values of doxy_adj_err (in umol/kg), compute NITRATE_ADJUSTED_ERROR \n",
    "    for all depth levels in umol/kg and write it to the given bgc_file.\n",
    "    NITRATE_ADJUSTED_ERROR = 1 µmol/kg + DOXY_ADJUSTED_ERROR/10\n",
    "    '''\n",
    "    # initialize the error with its full size, masked everywhere\n",
    "    nitr_adj_err = np.ma.masked_array(np.zeros(pres.shape), mask=True, fill_value=99999.0)\n",
    "    idx_good = np.where(~doxy_adj_err[this_iprof,:].mask  & ~nitr_adj[:].mask)\n",
    "    nitr_adj_err[this_iprof,idx_good] = 1.0 + 0.1 * doxy_adj_err[this_iprof,idx_good]\n",
    "    bgc_file.variables[\"NITRATE_ADJUSTED_ERROR\"][:,:] = nitr_adj_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26a2fdef-9656-4442-b1e4-0eb6164a1d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tcor(pres, temp, this_iprof, ref_depth=reference_depth):\n",
    "    '''\n",
    "    TCOR = (TREF+273.15) / (TEMP+273.15)\n",
    "    REF = TEMP at 1500m\n",
    "    '''\n",
    "    # determine the pressure level (for this_iprof) that's closest to the reference depth\n",
    "    idx_ref = np.argmin(abs(pres[this_iprof,:] - ref_depth))\n",
    "    # determine temperature at this pressure level\n",
    "    tref = temp[this_iprof,idx_ref]\n",
    "    tk = 273.15\n",
    "    tcor = (tref + tk) / (temp[this_iprof,:] + tk)\n",
    "    # determine reference pressure\n",
    "    if abs(pres[this_iprof,idx_ref] - ref_depth) < 50:\n",
    "        pres_ref = ref_depth\n",
    "    else:\n",
    "        # round to the nearest multiple of 50 dbar\n",
    "        pres_ref = 50 * round(pres[this_iprof,idx_ref] / 50)\n",
    "    return tcor, pres_ref # tcor is a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc2a8ac0-4c2e-4cca-985b-9e0fd5e57ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ph_adjusted(bgc_file, offset, tcor, gain, this_iprof):\n",
    "    '''Read PH_IN_SITU_TOTAL values, compute \n",
    "    PH_IN_SITU_TOTAL_ADJUSTED = [PH_IN_SITU_TOTAL - offset * tcor] / gain,\n",
    "    and write them to the BD file with the given file handle.\n",
    "    FIXME: non-zero values of PUMP_OFFSET are not yet handled\n",
    "    Full equation:\n",
    "    PH_IN_SITU_TOTAL_ADJUSTED=[PH_IN_SITU_TOTAL+[PUMP_OFFSET - [OFFSET + DRIFT(JULD-JULD_PIVOT)/365]*TCOR]]/GAIN\n",
    "    offset = OFFSET + DRIFT*(JULD-JULD_PIVOT)/365\n",
    "    TCOR=(TREF+273.15)./(TEMP+273.15)\n",
    "    TREF = TEMP at 1500m (in general: temperature at reference pressure)\n",
    "    Also write PH_IN_SITU_TOTAL_ADJUSTED_QC values.\n",
    "    Return the masked array PH_IN_SITU_TOTAL_Adjusted_Array.'''\n",
    "    ph = bgc_file.variables['PH_IN_SITU_TOTAL'][this_iprof,:]\n",
    "    ph_adjusted = (ph - offset * tcor) / gain\n",
    "    ph_adjusted_qc = np.empty(shape = (bgc_file.dimensions[\"N_LEVELS\"].size), dtype='|S1')\n",
    "    ph_adjusted_qc[:] = ' ' # use missing value as default\n",
    "    ph_adjusted_qc[~ph_adjusted.mask] = '2' # FIXME\n",
    "    # output to netcdf file\n",
    "    bgc_file.variables[\"PH_IN_SITU_TOTAL_ADJUSTED\"][this_iprof,:] = ph_adjusted\n",
    "    bgc_file.variables[\"PH_IN_SITU_TOTAL_ADJUSTED_QC\"][this_iprof,:] = ph_adjusted_qc\n",
    "    return ph_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a82917a9-e7a6-446e-8186-aa1b0c4b4b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ph_adjusted_error(bgc_file, ph_adj, pres, doxy_adj_err, this_iprof):\n",
    "    '''Given the values of doxy_adj_err (in umol/kg), compute PH_IN_SITU_TOTAL_ADJUSTED_ERROR \n",
    "    for all depth levels in umol/kg and write it to the given bgc_file.\n",
    "    PH_IN_SITU_TOTAL_ADJUSTED_ERROR = 0.01 + 0.0016*DOXY_ADJUSTED_ERROR\n",
    "    '''\n",
    "    # initialize the error with its full size, masked everywhere\n",
    "    ph_adj_err = np.ma.masked_array(np.zeros(pres.shape), mask=True, fill_value=99999.0)\n",
    "    idx_good = np.where(~doxy_adj_err[this_iprof,:].mask & ~ph_adj[:].mask)\n",
    "    idx_no_doxy_error = np.where(doxy_adj_err[this_iprof,:].mask & ~ph_adj[:].mask)\n",
    "    # if this_iprof != iprof_doxy, function interp_adj_err must have filled in doxy_adj_err with the correct profile for pH\n",
    "    ph_adj_err[this_iprof,idx_good] = 0.01 + 0.0016 * doxy_adj_err[this_iprof,idx_good]\n",
    "    ph_adj_err[this_iprof,idx_no_doxy_error] = 0.01 + 0.0016 * 5\n",
    "        \n",
    "    bgc_file.variables[\"PH_IN_SITU_TOTAL_ADJUSTED_ERROR\"][:,:] = ph_adj_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38103848-d2f2-4822-8272-46d45190095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_bad_profile(bgc_file, this_iprof):\n",
    "    '''This function is only used if all values in a profile are bad, \n",
    "    probably due to a failure of the sensor.\n",
    "    Includes setting of _QC values to 9 for base and adjusted variable'''\n",
    "    base_var = bgc_file.variables[variable][this_iprof,:] # only needed for size\n",
    "    adjusted_var = ma.masked_all_like(base_var)\n",
    "    # QC flag for the raw variable\n",
    "    base_qc = np.empty(shape = (bgc_file.dimensions[\"N_LEVELS\"].size), dtype='|S1')\n",
    "    base_qc[:] = ' ' # use missing value as default\n",
    "    base_qc[~base_var.mask] = '4' # all existing values are bad\n",
    "    bgc_file.variables[f\"{variable}_QC\"][this_iprof,:] = base_qc\n",
    "    # use the same QC values for the adjusted values\n",
    "    bgc_file.variables[f\"{variable}_ADJUSTED_QC\"][this_iprof,:] = base_qc\n",
    "    \n",
    "    # fill the masked array with NaN values\n",
    "    adjusted_var.fill_value = np.nan\n",
    "    \n",
    "    # output to netcdf file\n",
    "    bgc_file.variables[f\"{variable}_ADJUSTED\"][this_iprof,:] = adjusted_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "edc7e121-7923-4090-a1ab-bdd9b58b00a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profile(filename):\n",
    "    '''Extract the profile index from filename, return it as an int.'''\n",
    "    profile = filename[-6:-3]\n",
    "    return int(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cefa6025-bbdc-44bf-9c5a-a37f8d704c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract cycle, gain, offset, and drift values from ODV*QC.TXT file\n",
    "adjustments = {}\n",
    "for var in variables: \n",
    "    adjustments[var] = get_gain_offset_drift_odvqc(odv_filename, variable=var) # return value is a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62ea691c-8abc-4fb1-83f7-57e72eadf797",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "129 relevant B files found in /Users/madison.soden/Documents/MATLAB/ARGO_PROCESSING/DATA/ARGO_REPO/4903622/QC/\n",
      "JULD_INIT: 26210.909594934306\n",
      "   Station    Gain  Offset   Drift\n",
      "0      1.0  1.0521     0.0 -0.0009\n",
      "1    130.0  1.0489     0.0  0.0000\n",
      "Taking variable DOXY from profile 2\n",
      "N_HISTORY will be increased: True\n",
      "Processing /Users/madison.soden/Documents/MATLAB/ARGO_PROCESSING/DATA/ARGO_REPO/4903622/QC/BR4903622_001.nc\n",
      "<class 'int'>\n",
      "1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'doxy_adj_err' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 126\u001b[0m\n\u001b[1;32m    124\u001b[0m     doxy_adjusted \u001b[38;5;241m=\u001b[39m write_doxy_adjusted(bgc_file, gain)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m# calculate DOXY_ADJUSTED_ERROR in umol/kg    \u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m     write_doxy_adjusted_error(bgc_file, \u001b[43mdoxy_adj_err\u001b[49m, psal[iprof_phys,:], temp[iprof_phys,:], \n\u001b[1;32m    127\u001b[0m         pres_bgc[iprof,:], dens_phys[iprof_phys,:], doxy_adjusted)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m variable \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNITRATE\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;66;03m# compute and write NITRATE_ADJUSTED    \u001b[39;00m\n\u001b[1;32m    130\u001b[0m     nitr_adjusted \u001b[38;5;241m=\u001b[39m write_nitrate_adjusted(bgc_file, total_offset, current_adj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGain\u001b[39m\u001b[38;5;124m'\u001b[39m], this_iprof)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'doxy_adj_err' is not defined"
     ]
    }
   ],
   "source": [
    "# loop over all BR and BD files - they must be present in \"float_dir\" already\n",
    "all_bd_files = glob.glob(f'{float_dir}/BD*.nc')\n",
    "all_bd_files.sort()\n",
    "all_br_files = glob.glob(f'{float_dir}/BR*.nc')\n",
    "all_br_files.sort()\n",
    "\n",
    "print(glob.glob(f'{float_dir}/BD*.nc'))\n",
    "\n",
    "# if both BR and BD file exist for the same profile, only the BD file will be used\n",
    "sorted_b_files = organize_b_files(all_bd_files, all_br_files)\n",
    "print(f'{len(sorted_b_files)} relevant B files found in {float_dir}')\n",
    "#print(f'Sorted files: {sorted_b_files}')\n",
    "juld_init = get_variable(sorted_b_files[0], 'JULD')\n",
    "print(f'JULD_INIT: {juld_init}')\n",
    "    \n",
    "new_bd_files = list()                                 \n",
    "# need to keep track of previous JULD values to determine JULD_PIVOT from cycle\n",
    "juld = {} \n",
    "\n",
    "# how many profiles do the B files have?\n",
    "n_prof = get_dim_len(sorted_b_files[0], 'N_PROF')\n",
    "\n",
    "changed_iprof = [False] * n_prof\n",
    "\n",
    "# outer loop over variables\n",
    "for variable in variables:\n",
    "    # custom settings - bad profiles determined during DMQC process\n",
    "    if floatid == 4903499 and variable == 'PH_IN_SITU_TOTAL':\n",
    "        idx_prof_failure = 20 # first profile for which pH is completely bad\n",
    "    elif floatid == 4903500 and variable == 'PH_IN_SITU_TOTAL':\n",
    "        idx_prof_failure = 27 # first profile for which pH is completely bad\n",
    "    elif floatid == 4903622 and variable == 'PH_IN_SITU_TOTAL':\n",
    "        idx_prof_failure = 5 # first profile for which pH is completely bad\n",
    "    elif floatid == 4903624 and variable == 'PH_IN_SITU_TOTAL':\n",
    "        idx_prof_failure = 65 # first profile for which pH is completely bad \n",
    "    elif floatid == 4903622 and variable == 'PH_IN_SITU_TOTAL':\n",
    "        idx_prof_failure = 5 # first profile for which pH is completely bad\n",
    "    elif floatid == 4903624 and variable == 'NITRATE':\n",
    "        idx_prof_failure = 67 # first profile for which Nitrate is completely bad\n",
    "    else:\n",
    "        idx_prof_failure = 100000 # reset to \"never\"\n",
    "    print(adjustments[variable])\n",
    "    this_iprof = iprof[variable]\n",
    "    print(f'Taking variable {variable} from profile {this_iprof+1}') # count from 1 for humans\n",
    "    # always increase N_HISTORY for the first variable; for other variables, increase N_HISTORY\n",
    "    # only if an entry for the current profile was made for another variable already\n",
    "    if not any(changed_iprof) or changed_iprof[this_iprof]:\n",
    "        incr_hist_dim = True\n",
    "    else:\n",
    "        incr_hist_dim = False\n",
    "    changed_iprof[this_iprof] = True\n",
    "    print(f'N_HISTORY will be increased: {incr_hist_dim}')\n",
    "    \n",
    "    # inner loop over files\n",
    "    for bgc_filename in sorted_b_files:\n",
    "        print(f'Processing {bgc_filename}')\n",
    "        idx_profile = int(bgc_filename[-6:-3])\n",
    "        cycle = get_variable(bgc_filename, 'CYCLE_NUMBER')\n",
    "        if floatid == 4903622 and variable == 'PH_IN_SITU_TOTAL' and cycle >= 8:\n",
    "            print(f'Float {floatid} pH diabled for cycles {cycle}+ .\\nEnd pH processing')  \n",
    "            break #pH sensor was disabled, does not exist for cycle 8 and after\n",
    "        if floatid == 4903624 and variable == 'PH_IN_SITU_TOTAL' and cycle >= 68:\n",
    "            print(f'Float {floatid} pH diabled for cycles {cycle}+ .\\nEnd pH processing')  \n",
    "            break #pH sensor was disabled, does not exist for cycle or 68 and after\n",
    "    \n",
    "            \n",
    "        juld[cycle] = get_variable(bgc_filename, 'JULD')\n",
    "        compute_adjusted = True\n",
    "        \n",
    "        # check if sensor has gone bad\n",
    "        if idx_profile >= idx_prof_failure:\n",
    "            print(f'Profile {idx_profile} for {variable} is bad!')\n",
    "            profile_var_qc = 'F'\n",
    "            compute_adjusted = False\n",
    "           # if variable != 'PH_IN_SITU_TOTAL':\n",
    "           #     raise ValueError('case not yet handled')\n",
    "            juld_pivot = np.nan \n",
    "            current_adj = None # flag for function set_sci_calib_coefficients\n",
    "        else:\n",
    "            profile_var_qc = 'A' # FIXME\n",
    "            current_adj = get_current_gain_offset_drift(adjustments[variable], cycle)\n",
    "            juld_pivot = juld[int(current_adj['Station'])]\n",
    "\n",
    "        w_bgc_filename = create_working_bd_file(bgc_filename)    \n",
    "        bgc_file = netCDF4.Dataset(w_bgc_filename, 'a')\n",
    "        write_history(bgc_file, variable, this_iprof, incr_hist_dim)\n",
    "        write_parameter_data_mode(bgc_file, this_iprof)\n",
    "        sci_calib_coeffs = set_sci_calib_coefficients(current_adj, juld[cycle], juld_pivot)\n",
    "        #DEBUG print(sci_calib_coeffs)\n",
    "\n",
    "        bgc_file.variables[\"DATA_STATE_INDICATOR\"][this_iprof] = np.ma.array(data_state_indicator, \n",
    "                                                                    mask=[False, False, True, True], \n",
    "                                                                    dtype='|S1')\n",
    "\n",
    "        # need to determine which pTS profile index to use FIXME this comment\n",
    "        phys_filename = get_phys_filename(bgc_filename)\n",
    "        pres_phys_raw = get_phys_raw_pres(phys_filename)\n",
    "        pres_bgc = bgc_file.variables['PRES'][:,:]\n",
    "        # both profiles should have matching pressure values in phys and bgc files\n",
    "        if max(abs(pres_phys_raw[0,:]-pres_bgc[0,:])) > 0.0 or max(abs(pres_phys_raw[1,:]-pres_bgc[1,:])) > 0.0:\n",
    "            raise ValueError('mismatch in pressure values')\n",
    "        #FIXME UNNEEDED iprof_phys = get_iprof_phys(pres_phys_raw, pres_bgc)\n",
    "\n",
    "        if variable == 'DOXY' or variable == 'PH_IN_SITU_TOTAL':\n",
    "            # extract variables from corresponding physical profile file\n",
    "            dens, psal, temp = get_dens(phys_filename)\n",
    "\n",
    "        if variable != 'DOXY':\n",
    "            # adjusted error of nitrate and pH is derived from DOXY_ADJUSTED_ERROR\n",
    "            doxy_adj_err = bgc_file.variables['DOXY_ADJUSTED_ERROR'][:,:]\n",
    "            if this_iprof != iprof['DOXY']:\n",
    "                # interpolate DOXY_ADJUSTED_ERROR to the other pressure axis\n",
    "                doxy_adj_err = interp_adj_err(doxy_adj_err, pres_bgc, iprof['DOXY'], this_iprof)\n",
    "\n",
    "        # compute total_offset for this profile\n",
    "        total_offset = get_total_offset(current_adj, juld[cycle], juld_pivot)\n",
    "        #DEBUG print(total_offset)\n",
    "        this_sci_calib_eqn = sci_calib_eqn[variable]\n",
    "        \n",
    "        if compute_adjusted:\n",
    "            if variable == 'DOXY':\n",
    "                # compute DOXY_ADJUSTED from DOXY and gain value and write it to BD file \n",
    "                gain = 1.0489\n",
    "                doxy_adjusted = write_doxy_adjusted(bgc_file, gain)\n",
    "                # calculate DOXY_ADJUSTED_ERROR in umol/kg    \n",
    "                write_doxy_adjusted_error(bgc_file, doxy_adj_err, psal[iprof_phys,:], temp[iprof_phys,:], \n",
    "                    pres_bgc[iprof,:], dens_phys[iprof_phys,:], doxy_adjusted)\n",
    "            elif variable == 'NITRATE':\n",
    "                # compute and write NITRATE_ADJUSTED    \n",
    "                nitr_adjusted = write_nitrate_adjusted(bgc_file, total_offset, current_adj['Gain'], this_iprof)\n",
    "                # calculate NITRATE_ADJUSTED_ERROR in umol/kg from DOXY_ADJUSTED_ERROR and write it to BD file   \n",
    "                write_nitrate_adjusted_error(bgc_file, nitr_adjusted, pres_bgc, doxy_adj_err, this_iprof)\n",
    "            elif variable == 'PH_IN_SITU_TOTAL':\n",
    "                tcor, pres_ref = compute_tcor(pres_phys_raw, temp, this_iprof)\n",
    "                ph_adjusted = write_ph_adjusted(bgc_file, total_offset, tcor, current_adj['Gain'], this_iprof)\n",
    "                if abs(pres_ref - reference_depth) > 0.1:\n",
    "                    regex = re.compile(rf'({reference_depth})\\s*m')\n",
    "                    match_obj = regex.search(this_sci_calib_eqn)\n",
    "                    if match_obj:\n",
    "                        this_sci_calib_eqn = this_sci_calib_eqn.replace(match_obj.group(1), f'{pres_ref}')\n",
    "                    else:\n",
    "                        raise ValueError('no string with reference depth found in sci calib equation')\n",
    "                # calculate PH_IN_SITU_TOTAL_ADJUSTED_ERROR in umol/kg from DOXY_ADJUSTED_ERROR and write it to BD file   \n",
    "                write_ph_adjusted_error(bgc_file, ph_adjusted, pres_bgc, doxy_adj_err, this_iprof)\n",
    "            else:\n",
    "                raise ValueError('not yet coded')\n",
    "        else:\n",
    "            write_bad_profile(bgc_file, this_iprof) # writes _ADJUSTED, _ADJUSTED_QC, _QC values\n",
    "        # reference depth that was used for pH may differ from default; content may have been changed\n",
    "        #DEBUG print(sci_calib_coeffs)\n",
    "        write_scientific_calib(bgc_file, sci_calib_coeffs, this_sci_calib_eqn, this_iprof)\n",
    "\n",
    "        # assign a new overall profile QC flag\n",
    "        prof_qc_name = f'PROFILE_{variable}_QC'\n",
    "        bgc_file.variables[prof_qc_name][this_iprof] = profile_var_qc\n",
    "\n",
    "        # fix the vertical sampling scheme entry FIXME\n",
    "        if variable == variables[0]:\n",
    "            str_dim = bgc_file.dimensions[bgc_file['VERTICAL_SAMPLING_SCHEME'].dimensions[-1]]\n",
    "            vss0 = 'Primary sampling: averaged [binned data sampled at 1.0 Hz from a SBE41CP; nominal 2 dbar to 1000 bar, 4 dbar below 1000 dbar]'\n",
    "            bgc_file['VERTICAL_SAMPLING_SCHEME'][0,:] = string_to_array(vss0, str_dim)\n",
    "            vss1 = 'Secondary sampling: discrete [from the same SBE41CP]'\n",
    "            bgc_file['VERTICAL_SAMPLING_SCHEME'][1,:] = string_to_array(vss1, str_dim)            \n",
    "            vss = bgc_file['VERTICAL_SAMPLING_SCHEME'][:]\n",
    "\n",
    "        bgc_file.close()\n",
    "        new_bd_files.append(w_bgc_filename)\n",
    "\n",
    "        print(f'Renaming {w_bgc_filename} to {bgc_filename}')\n",
    "        os.rename(w_bgc_filename, bgc_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eae6a78a-feb9-487a-8aaa-a89119b9ceb9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These BD files were created or modified:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print('These BD files were created or modified:')\n",
    "print(new_bd_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45fcec9-d215-4a53-b594-1215769824cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_bd_files = glob.glob(f'{float_dir}BD*{floatid}_*.nc')\n",
    "print(all_bd_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63a96ed-84e0-4aea-8c15-bf0b5716fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bgc_file = netCDF4.Dataset('/Users/madison.soden/Desktop/4903622_V1_Nit_pH/BD4903622_095.nc', 'a')\n",
    "#bgc_file.variables[\"PROFILE_NITRATE_QC\"][1]= bytes(' ', 'utf-8')\n",
    "#bgc_file.variables[\"PROFILE_NITRATE_QC\"]\n",
    "#bgc_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c2589f-ebc8-4e46-a819-55864a2aee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bgc_file.variables[\"PROFILE_RPHASE_DOXY_QC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a00400-e63c-4537-96ce-9027fbded6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bgc_file = netCDF4.Dataset('/Users/madison.soden/Desktop/4903625_sus/BD4903625_017.nc', 'a')\n",
    "#bgc_file.variables[\"PROFILE_PH_IN_SITU_TOTAL_QC\"][1]= bytes(' ', 'utf-8')\n",
    "#bgc_file.variables[\"PROFILE_PH_IN_SITU_TOTAL_QC\"]\n",
    "#bgc_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa867f7-fa2b-47fc-9771-18ab28273e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f6c31f-5326-42c3-8404-d2ee89fbe775",
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(f'{float_dir}/BR*.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a5f6be-625d-4472-9e66-06d6f8eb0237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Argo_jupyter] *",
   "language": "python",
   "name": "conda-env-Argo_jupyter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
